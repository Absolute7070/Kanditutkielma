{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39087066-0f35-40ef-8b06-626ad63d6eaf",
   "metadata": {},
   "source": [
    "# The optimization of the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81510bd0-538d-4546-a4e6-8a5618ec53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 07:18:53.765946: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 07:19:01.079510: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-01 07:19:01.079569: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-01 07:19:04.139205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-01 07:19:04.139274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-01 07:19:04.139281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # for implementing optimization\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, '/home/degnaiyu/Työpöytä/kanditutkielma/kandityo_koodit/main')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5dcb82-9d89-4234-9d0a-cd3f167b4c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f9f176-b5af-418f-b0d7-7e9fb328a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import parameters as pr  \n",
    "import monteCarloIntegration as mc \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2477b785-36e0-4e4b-8977-c01b537a65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym \n",
    "from sympy import symbols, diff, lambdify \n",
    "\n",
    "import re \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f177e-f74f-4faf-8e3f-9960ec4f0390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94ccfd6-5a12-41b6-a453-e5960e282ea6",
   "metadata": {},
   "source": [
    "**Testattu**\n",
    "1. metropolisSamplingFunction ja monteCarloIntegrationFunction, joilla on parametrit,  voivat korvata vanhemmat vastaavat funktiot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "992f5de5-9459-4f9a-99e2-eae8f06d316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i: k for i,k in zip(range(10), range(10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bbb60-5c67-4f7e-970d-08b2a4fcdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(expr, paramVariables: list, initialParamValues: list, learning_rate: float = 0.001): \n",
    "    '''\n",
    "    Compute gradient descent from sympy expression, which has symbols. \n",
    "    \n",
    "    Gradient descent update algorithm: alpha_i = alpha_(i-1)- learning_rate * gradient(expr)\n",
    "    \n",
    "    - expr: sympy expression \n",
    "    - paramVariables: list of sympy symbols used in the \"expr\". e.g. [sym.Symbol('a'), sym.Symbol('b')]\n",
    "    - paramValues: current values of the parameters. Acts as initial values.\n",
    "    - learning rate \n",
    "    '''\n",
    "    partialDerivativeList = [diff(expr, variable) for variable in paramVariables ]        # list of partial derivatives with possible variables in the expr\n",
    "    \n",
    "    paramValuesList = initialParamValues.copy()\n",
    "    \n",
    "    #Perform gradient descent\n",
    "    for i in range(100):\n",
    "        \n",
    "        \n",
    "        # update each parameter value with negative gradient descent \n",
    "        for index in range(len(paramValuesList)): \n",
    "            paramValuesList[index] -= partialDerivativeList[index].evalf(subs={paramVariables[0]:paramValuesList[len(paramValuesList)-2], sym.Symbol('b'):paramValuesList[len(paramValuesList)-1]})*lr \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d78a31-1e3c-424c-b433-d8935376450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x, params): \n",
    "    return x[0]+ x[1]+ params[0]* params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285ffc72-1a7f-442a-88e8-cd1301597d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 10 a b + 90$"
      ],
      "text/plain": [
       "10*a*b + 90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramVariableList = [sym.Symbol('a'), sym.Symbol('b')]\n",
    "f1 = np.sum([ function([i,k ], paramVariableList) for  i, k in zip(range(10), range(10))])\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e960b9-7f9f-478f-bbd3-4f03ce6b5ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10*b, 10*a]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through possible partial derivative \n",
    "partialDerivativeList = [diff(f1, variable) for variable in paramVariableList ]\n",
    "partialDerivativeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43972187-f631-4879-9bf9-707fd47ad339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function optimized for numpy array calculation\n",
    "# in sympy \n",
    "f = lambdify(paramVariableList, f1, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db651f-b52f-4c9e-b877-4f246f3b513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae9ef446-90e4-4e6b-8b00-77a21885c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a start point\n",
    "alpha_beta = [3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16c4e710-08f2-43c7-aacd-5c2c07dd1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#Specify the learning rate\n",
    "lr=0.001\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b46877c-51d6-4198-8c7e-a1a028b129c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta[len(alpha_beta)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb4b7847-aa44-436b-8fe4-57d2d0a6a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform gradient descent\n",
    "for i in range(100):\n",
    "    # Update the a and b values using the negative gradient values\n",
    "    \n",
    "    # update each parameter with negative gradient descent \n",
    "    for index in range(len(alpha_beta)): \n",
    "        alpha_beta[index] -= partialDerivativeList[index].evalf(subs={sym.Symbol('a'):alpha_beta[len(alpha_beta)-2], sym.Symbol('b'):alpha_beta[len(alpha_beta)-1]})*lr \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bfa7cd9-8c5e-4a1f-89c8-0295020286fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.08605928982408, 1.12131469206103]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3067f4-9ad7-479c-aa43-36e2b0ee76c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b313f34e-b6ef-4840-8439-395b5c72de95",
   "metadata": {},
   "source": [
    "# Global values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cb5f51-c5ed-4dc5-86ff-f5f6464d96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyTable = {'Energy': [], 'Variance':[], 'Std error of mean': [], 'parameters': []}\n",
    "\n",
    "def saveToHistoryTable(energyAndErrors: tuple or list, params: float or list or tuple): \n",
    "    '''\n",
    "    Save integration results to the table historyTable (global value)\n",
    "    \n",
    "    - energyAndErrors: energy and their errors in format (energy, variance, std error of mean)\n",
    "    - parameters: parameters.\n",
    "        - it is float-type if there is only one parameter \n",
    "        - it is list or tuple-type if there are more than one parameter\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    historyTable['Energy'].append(energyAndErrors[0])\n",
    "    historyTable['Variance'].append(energyAndErrors[1])\n",
    "    historyTable['Std error of mean'].append(energyAndErrors[2])\n",
    "    historyTable['parameters'].append(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bbc09-0802-439d-8e4a-cd4f5ba51f14",
   "metadata": {},
   "source": [
    "# Algorithm (Helium, 1 parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdb6436-4395-44d5-a976-31bd87a2b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all relying on FortranForm \n",
    "\n",
    "\n",
    "def probabilityFunction(x: np.ndarray, params: list): \n",
    "    particleOnexyz = x[0] \n",
    "    particleTwoxyz = x[1]\n",
    "    return (\n",
    "        np.exp(-2*params[0]*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def localEnergyFunction(x: np.ndarray, params: list ): \n",
    "    particleOnexyz = x[0] \n",
    "    particleTwoxyz = x[1]\n",
    "    \n",
    "    \n",
    "    return (  \n",
    "        -params[0]**2 - 2/np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - 2/np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + 1/np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - 2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2) + params[0]*(1/np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + 1/np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2))\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef33de-9d8f-4fb8-a481-4d4e36994dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb91709-1858-4c6c-8579-94977b297162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4771e6-beb4-4b4b-b553-db88449dfb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ab74d8-1e80-44a1-aae3-ac89f02001ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MUST BE FLOAT!!!\n",
    "alpha = 2.0   # initial guess of the parameter\n",
    "params = [alpha]\n",
    "paramsVariable = [tf.placeholder(tf.float32)]\n",
    "\n",
    "\n",
    "patience = 1 # how many times we accept the energy to jump to higher value than the previous energy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a98bba-9122-49ab-a5df-d61305015b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 10:05:30.648545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-31 10:05:30.648564: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-31 10:05:30.648578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lx0-fuxi138): /proc/driver/nvidia/version does not exist\n",
      "2023-01-31 10:05:30.649559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loopMark = 0 # which loop we are going on \n",
    "\n",
    "while patience >= 0: \n",
    "\n",
    "    configSamples_Metropolis = mc.metropolisSamplingFunction(coordinateValueRange = (-1, 1), \n",
    "                                                         numberOfParticles = 2, \n",
    "                                                         numberOfConfig = 3000, \n",
    "                                                         probabilityFunction = probabilityFunction, \n",
    "                                                        numberOfIterations= 1000, \n",
    "                                                          params = [alpha]\n",
    "                                                         ) \n",
    "\n",
    "\n",
    "\n",
    "    # integration approximation using current parameter value \n",
    "    integrationResultAsValue = mc.monteCarloIntegrationFunction(configSamples_Metropolis, localEnergyFunction = localEnergyFunction,  params= [alpha], needError = True)\n",
    "    # save the results to the table \n",
    "    saveToHistoryTable(integrationResultAsValue, alpha)\n",
    "\n",
    "\n",
    "\n",
    "    # integration approximation with parameter as variable for optimization \n",
    "    integrationResultWithParameter = mc.monteCarloIntegrationFunction(configSamples_Metropolis, localEnergyFunction = localEnergyFunction,  params= [sym.Symbol('a')])\n",
    "\n",
    "\n",
    "    # extract coefficients from previous integration as float \n",
    "    listOfCoefficients =list( map(lambda x: float(x), re.findall(r'[-]?\\d+[.]{1}\\d+', str(integrationResultWithParameter[0]).replace(' ', '')) ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # optimization using Adam \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.1)   # define optimizer \n",
    "    var = tf.Variable(alpha)                         # define current variable value \n",
    "    loss = lambda: listOfCoefficients[0] * var**2 + listOfCoefficients[1]*var + listOfCoefficients[2]   # define loss function \n",
    "    opt.minimize(loss, [var])                 # minimize 1 step   # possible to minimize further? -> more loops \n",
    "\n",
    "    alpha = var.numpy()                   \n",
    "    \n",
    "    # when we have at least two energy values in the table, we can compare them \n",
    "    if loopMark >= 1: \n",
    "        # if current calculated energy is bigger than energy calculated in the previous loop, reduce patience by 1\n",
    "        if historyTable['Energy'][-1] > historyTable['Energy'][-2]: \n",
    "            patience -= 1\n",
    "    \n",
    "    print(loopMark) \n",
    "    \n",
    "    loopMark += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b167b2-f222-4fce-8b50-746cb7d71d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Energy': [-2.752675563923704,\n",
       "  -2.6640466113447343,\n",
       "  -2.746698474556848,\n",
       "  -2.810050843951516,\n",
       "  -2.7578758951641067],\n",
       " 'Variance': [1.1194246655350968,\n",
       "  1.4065949990980284,\n",
       "  1.1189714068211458,\n",
       "  0.5918687289431723,\n",
       "  1.1584071954531296],\n",
       " 'Std error of mean': [0.019316872292852318,\n",
       "  0.02165329073603693,\n",
       "  0.019312961164471436,\n",
       "  0.014045980788623869,\n",
       "  0.019650336684589143],\n",
       " 'parameters': [2.0, 2.0999916, 2.0000017, 1.9000399, 2.000033]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b20ad8-4bf8-447d-bd59-d43a37c6727b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0436a-ca85-4dbd-a039-cfc2bc793bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c284488-54c8-49ee-9b4a-782c16c83271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e06d95e3-8e3f-4821-aad0-eca89b647485",
   "metadata": {},
   "source": [
    "# Testaus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcf3d7-4cf0-4e0c-be2c-f4da768ebd1c",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc2eda16-9c78-40c7-9c3b-f3a2ada1d4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-1.0', '3.98813746927895', '-6.72856476573052']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '-1.0*a**2 + 3.98813746927895*a - 6.72856476573052'\n",
    "re.findall(r'[-]?\\d+[.]{1}\\d+', string.replace(' ', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ee2f8-84ee-45de-bb82-ac4859a0199f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
