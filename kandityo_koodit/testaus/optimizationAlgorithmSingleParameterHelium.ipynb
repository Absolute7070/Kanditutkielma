{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39087066-0f35-40ef-8b06-626ad63d6eaf",
   "metadata": {},
   "source": [
    "# The optimization of the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81510bd0-538d-4546-a4e6-8a5618ec53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # for implementing optimization\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, '/home/degnaiyu/Työpöytä/kanditutkielma/kandityo_koodit/main')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5dcb82-9d89-4234-9d0a-cd3f167b4c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30f9f176-b5af-418f-b0d7-7e9fb328a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import parameters as pr  \n",
    "import monteCarloIntegration as mc \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2477b785-36e0-4e4b-8977-c01b537a65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym \n",
    "from sympy import symbols, diff, lambdify \n",
    "\n",
    "import re \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f177e-f74f-4faf-8e3f-9960ec4f0390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94ccfd6-5a12-41b6-a453-e5960e282ea6",
   "metadata": {},
   "source": [
    "**Testattu**\n",
    "1. metropolisSamplingFunction ja monteCarloIntegrationFunction, joilla on parametrit,  voivat korvata vanhemmat vastaavat funktiot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec9bbb60-5c67-4f7e-970d-08b2a4fcdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testattu \n",
    "def gradientDescentFunc(expr, paramVariables: list, initialParamValues: list,learning_rate: float = 0.001,  limitForLoop: int = 100): \n",
    "    '''\n",
    "    Compute gradient descent from sympy expression, which has symbols. \n",
    "    \n",
    "    Gradient descent update algorithm: alpha_i = alpha_(i-1)- learning_rate * gradient(expr)\n",
    "    \n",
    "    - expr: sympy expression \n",
    "    - paramVariables: list of sympy symbols used in the \"expr\". e.g. [sym.Symbol('a'), sym.Symbol('b')]\n",
    "    - paramValues: current values of the parameters. Acts as initial values.\n",
    "    - learning rate \n",
    "    \n",
    "    \n",
    "    \n",
    "    Example: simple usage \n",
    "    \n",
    "        # Define the sympy symbols to be used in the function\n",
    "        x = symbols('x')\n",
    "        y = symbols('y')\n",
    "        #Define the function in terms of x and y\n",
    "        f1 = (x-2) ** 2 + (y-2)**2+5      # sympy expression \n",
    "\n",
    "\n",
    "        paramVariables = [x, y]\n",
    "        initialParamValues = [3.0, 3.0]\n",
    "\n",
    "        gradientDescentFunc(f1, paramVariables = paramVariables, initialParamValues = initialParamValues )\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # error check: whether the length of paramVariables is the same as initialParamValues \n",
    "    if (len(paramVariables) != len(initialParamValues)): \n",
    "        print('Error: Length of the list of initial values must be the same as number of symbolic variables!!!')\n",
    "        return \n",
    "    \n",
    "    \n",
    "    partialDerivativeList = [diff(expr, variable) for variable in paramVariables ]   # list of partial derivatives with respect to possible variables in the expr\n",
    "    \n",
    "    paramValuesList = initialParamValues.copy()  # list of parameter values, each representing its own parameter e.g. [2.0, 2.0] for [alpha, beta]\n",
    "    \n",
    "    \n",
    "    # dictionary with format: \n",
    "    #     {\n",
    "    #         sym.Symbol('a'):3, \n",
    "    #         sym.Symbol('b'):4, \n",
    "\n",
    "    #     }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # list of gradients for determining when to cut the loop \n",
    "    # if parameters reached minimum, gradient should be zero\n",
    "    gradientList = np.random.randint(low = 100, size = len(paramValuesList))  # initiating gradientList with random large numbers\n",
    "\n",
    "    \n",
    "    \n",
    "    counter = 0 \n",
    "    #Perform gradient descent\n",
    "    while ( np.array(gradientList) < 0.001).all() == False :         # if all gradients are bigger or equal to 0.1, continue descending \n",
    "        counter += 1 \n",
    "        \n",
    "        # clean the list\n",
    "        gradientList = []\n",
    "        \n",
    "        # update each parameter value with negative gradient descent \n",
    "        for index in range(len(paramValuesList)): \n",
    "            # for later substitution when evaluating derivatives  \n",
    "            substitutionDict = {paramVariables[i]:paramValuesList[i] for i in range(len(paramVariables))}\n",
    "                \n",
    "                \n",
    "            # gradient-descenting one parameter \n",
    "            paramValuesList[index] -= partialDerivativeList[index].evalf(subs=substitutionDict)*learning_rate\n",
    "            \n",
    "            gradientList.append(partialDerivativeList[index].evalf(subs=substitutionDict))  # appending the gradient to the list \n",
    "        \n",
    "\n",
    "        \n",
    "        # if user not wanting for too much loops, or not wanting to reach the local minimum,\n",
    "        # or loop last too long, break the loop \n",
    "        if counter >= limitForLoop: \n",
    "            break \n",
    "    \n",
    "    \n",
    "    return paramValuesList\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313f34e-b6ef-4840-8439-395b5c72de95",
   "metadata": {},
   "source": [
    "# Global values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66cb5f51-c5ed-4dc5-86ff-f5f6464d96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyTable = {'Energy': [], 'Variance':[], 'Std error of mean': [], 'parameters': []}\n",
    "\n",
    "def saveToHistoryTable(energyAndErrors: tuple or list, params: float or list or tuple): \n",
    "    '''\n",
    "    Save integration results to the table historyTable (global value)\n",
    "    \n",
    "    - energyAndErrors: energy and their errors in format (energy, variance, std error of mean)\n",
    "    - parameters: parameters.\n",
    "        - it is float-type if there is only one parameter \n",
    "        - it is list or tuple-type if there are more than one parameter\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    historyTable['Energy'].append(energyAndErrors[0])\n",
    "    historyTable['Variance'].append(energyAndErrors[1])\n",
    "    historyTable['Std error of mean'].append(energyAndErrors[2])\n",
    "    historyTable['parameters'].append(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bbc09-0802-439d-8e4a-cd4f5ba51f14",
   "metadata": {},
   "source": [
    "# Algorithm (Helium, 1 parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4fdb6436-4395-44d5-a976-31bd87a2b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all relying on FortranForm \n",
    "\n",
    "\n",
    "def probabilityFunction(x: np.ndarray, params: list): \n",
    "    particleOnexyz = x[0] \n",
    "    particleTwoxyz = x[1]\n",
    "    \n",
    "    \n",
    "    return (\n",
    "        sym.exp(-2*params[0]*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def localEnergyFunction(x: np.ndarray, params: list ): \n",
    "    particleOnexyz = x[0] \n",
    "    particleTwoxyz = x[1]\n",
    "    \n",
    "    \n",
    "    return (  \n",
    "        -params[0]**2 - 2/np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - 2/np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + 1/np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - 2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2) + params[0]*(1/np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + 1/np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2))\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90ab74d8-1e80-44a1-aae3-ac89f02001ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MUST BE FLOAT!!!\n",
    "alpha = 2.0   # initial guess of the parameter\n",
    "paramsValuesList = [alpha]\n",
    "paramsVariableList = [sym.Symbol('a')]\n",
    "\n",
    "\n",
    "patience = 1 # how many times we accept the energy to jump to higher value than the previous energy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63a98bba-9122-49ab-a5df-d61305015b00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramsValuesList [2.0]\n",
      "0\n",
      "paramsValuesList [2.0000052673891466]\n",
      "1\n",
      "paramsValuesList [1.989841683878321]\n",
      "2\n",
      "paramsValuesList [1.989877989583803]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loopMark = 0 # which loop we are going on \n",
    "\n",
    "while patience >= 0: \n",
    "    \n",
    "\n",
    "    configSamples_Metropolis = mc.metropolisSamplingFunction(coordinateValueRange = (-1, 1), \n",
    "                                                         numberOfParticles = 2, \n",
    "                                                         numberOfConfig = 3000, \n",
    "                                                         probabilityFunction = probabilityFunction, \n",
    "                                                        numberOfIterations= 1000, \n",
    "                                                          params =  paramsValuesList\n",
    "                                                         ) \n",
    "\n",
    "    \n",
    "\n",
    "    # integration approximation using current parameter value \n",
    "    integrationResultAsValue = mc.monteCarloIntegrationFunction(configSamples_Metropolis, localEnergyFunction = localEnergyFunction,  params= paramsValuesList, needError = True)\n",
    "    # save the results to the table \n",
    "    saveToHistoryTable(integrationResultAsValue, paramsValuesList)\n",
    "\n",
    "\n",
    "\n",
    "    # integration approximation with parameter as variable for optimization \n",
    "    # return tuple, where first is the integration result with parameters as variables\n",
    "    integrationResultWithParameter = mc.monteCarloIntegrationFunction(configSamples_Metropolis, localEnergyFunction = localEnergyFunction,  params= paramsVariableList)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # optimization: gradient descent \n",
    "    \n",
    "    # replace the current parameter values with optimized parameter values \n",
    "    paramsValuesList = gradientDescentFunc(\n",
    "        expr = integrationResultWithParameter[0],  # integration result with parameter \n",
    "         paramVariables= paramsVariableList,        # list of symbolic variables representing parameters to be optimized \n",
    "        initialParamValues= paramsValuesList        # current parameter values as float \n",
    "    )   \n",
    "    \n",
    "    \n",
    "     # transfrom to python float. Avoid issues with sympy.float and numpy.ufunc incompatibility \n",
    "    paramsValuesList = list(map(float, paramsValuesList))     \n",
    "                  \n",
    "    \n",
    "    # when we have at least two energy values in the table, we can compare them \n",
    "    if loopMark >= 1: \n",
    "        # if current calculated energy is bigger than energy calculated in the previous loop, reduce patience by 1\n",
    "        if historyTable['Energy'][-1] > historyTable['Energy'][-2]: \n",
    "            patience -= 1\n",
    "    \n",
    "    print(loopMark) \n",
    "    \n",
    "    loopMark += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8b167b2-f222-4fce-8b50-746cb7d71d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Energy': [-2.7525106939324964,\n",
       "  -2.7150608497232955,\n",
       "  -2.7670800496142323,\n",
       "  -2.7534667470518457],\n",
       " 'Variance': [1.0158604794611872,\n",
       "  0.9921219181198913,\n",
       "  1.0386948868176162,\n",
       "  2.30538618802505],\n",
       " 'Std error of mean': [0.01840163470511236,\n",
       "  0.018185359662100824,\n",
       "  0.01860730042051252,\n",
       "  0.027721148292865084],\n",
       " 'parameters': [[2.0],\n",
       "  [2.0000052673891466],\n",
       "  [1.989841683878321],\n",
       "  [1.989877989583803]]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3364e0a-82dd-4d2e-8fd9-40868e7eb5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b27b6-b78f-427c-9c2e-60ee22ae4760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd8dd6-1103-4cd8-bec7-beaa5add716e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e06d95e3-8e3f-4821-aad0-eca89b647485",
   "metadata": {},
   "source": [
    "# Testaus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcf3d7-4cf0-4e0c-be2c-f4da768ebd1c",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2eda16-9c78-40c7-9c3b-f3a2ada1d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '-1.0*a**2 + 3.98813746927895*a - 6.72856476573052'\n",
    "re.findall(r'[-]?\\d+[.]{1}\\d+', string.replace(' ', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ee2f8-84ee-45de-bb82-ac4859a0199f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
