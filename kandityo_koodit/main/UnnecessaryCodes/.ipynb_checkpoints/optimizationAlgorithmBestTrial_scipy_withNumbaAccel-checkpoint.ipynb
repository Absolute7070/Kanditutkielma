{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd095a1-1964-4bf1-b2b2-e92f8ad9de78",
   "metadata": {},
   "source": [
    "# Best trial for Helium "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39087066-0f35-40ef-8b06-626ad63d6eaf",
   "metadata": {},
   "source": [
    "# The optimization of the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81510bd0-538d-4546-a4e6-8a5618ec53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 06:41:13.401730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 06:41:13.553729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-05 06:41:13.553745: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-05 06:41:14.292924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 06:41:14.292991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 06:41:14.293012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # for implementing optimization\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "import parameters as pr  \n",
    "import functions_module as mc \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2477b785-36e0-4e4b-8977-c01b537a65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym \n",
    "from sympy import symbols, diff, lambdify \n",
    "from numba import jit \n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import re \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ccfd6-5a12-41b6-a453-e5960e282ea6",
   "metadata": {},
   "source": [
    "**Testattu**\n",
    "1. metropolisSamplingFunction ja monteCarloIntegrationFunction, joilla on parametrit,  voivat korvata vanhemmat vastaavat funktiot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313f34e-b6ef-4840-8439-395b5c72de95",
   "metadata": {},
   "source": [
    "# Global values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cb5f51-c5ed-4dc5-86ff-f5f6464d96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyTable = {'Energy': [], 'Variance':[], 'Std error of mean': [], 'parameters': []}\n",
    "\n",
    "def saveToHistoryTable(energyAndErrors: tuple or list, params: float or list or tuple): \n",
    "    '''\n",
    "    Save integration results to the table historyTable (global value)\n",
    "    \n",
    "    - energyAndErrors: energy and their errors in format (energy, variance, std error of mean)\n",
    "    - parameters: parameters.\n",
    "        - it is float-type if there is only one parameter \n",
    "        - it is list or tuple-type if there are more than one parameter\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    historyTable['Energy'].append(energyAndErrors[0])\n",
    "    historyTable['Variance'].append(energyAndErrors[1])\n",
    "    historyTable['Std error of mean'].append(energyAndErrors[2])\n",
    "    historyTable['parameters'].append(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bbc09-0802-439d-8e4a-cd4f5ba51f14",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdb6436-4395-44d5-a976-31bd87a2b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jit(nopython = True )\n",
    "def probabilityFunction(x: np.ndarray, params: list): \n",
    "    particleOnexyz = x[0] \n",
    "    particleTwoxyz = x[1]\n",
    "    return (\n",
    "        (1 + params[1]*np.sqrt((particleOnexyz[0] - particleTwoxyz[0])**2 + (particleOnexyz[1] - particleTwoxyz[1])**2 + (particleOnexyz[2] - particleTwoxyz[2])**2))**2/\n",
    "     -  np.exp(2*params[0]*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)))\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def localEnergyFunction(x: np.ndarray, params: list ): \n",
    "    particleOnexyz = x[0] \n",
    "    particleTwoxyz = x[1]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return (  \n",
    "                    (np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -    2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -     np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - \n",
    "         -       2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2) - \n",
    "         -    2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)*\n",
    "         -     np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - \n",
    "         -       2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2) - \n",
    "         -    params[0]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)*\n",
    "         -     np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - \n",
    "         -       2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2) + \n",
    "         -    params[0]*np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - \n",
    "         -       2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2)*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -       np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)) - \n",
    "         -    params[1]*(2*particleOnexyz[1]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - \n",
    "         -       params[0]*particleOnexyz[1]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - \n",
    "         -       4*particleOnexyz[1]*particleTwoxyz[1]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -       3*params[0]*particleOnexyz[1]*particleTwoxyz[1]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -       2*particleTwoxyz[1]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - \n",
    "         -       2*params[0]*particleTwoxyz[1]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -       2*particleOnexyz[2]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - \n",
    "         -       params[0]*particleOnexyz[2]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) - \n",
    "         -       4*particleOnexyz[2]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*particleTwoxyz[2] + \n",
    "         -       3*params[0]*particleOnexyz[2]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*particleTwoxyz[2] + \n",
    "         -       2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*particleTwoxyz[2]**2 - \n",
    "         -       2*params[0]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*particleTwoxyz[2]**2 + \n",
    "         -       2*particleOnexyz[1]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       2*params[0]*particleOnexyz[1]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       4*particleOnexyz[1]*particleTwoxyz[1]*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       3*params[0]*particleOnexyz[1]*particleTwoxyz[1]*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       2*particleTwoxyz[1]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       params[0]*particleTwoxyz[1]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       2*particleOnexyz[2]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       2*params[0]*particleOnexyz[2]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       params[0]**2*particleOnexyz[1]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -        np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       2*params[0]**2*particleOnexyz[1]*particleTwoxyz[1]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -        np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       params[0]**2*particleTwoxyz[1]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -        np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       params[0]**2*particleOnexyz[2]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -        np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       4*particleOnexyz[2]*particleTwoxyz[2]*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       3*params[0]*particleOnexyz[2]*particleTwoxyz[2]*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       2*params[0]**2*particleOnexyz[2]*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*particleTwoxyz[2]*\n",
    "         -        np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       2*particleTwoxyz[2]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       params[0]*particleTwoxyz[2]**2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -       params[0]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*particleTwoxyz[2]**2*\n",
    "         -        np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -       np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)*\n",
    "         -        np.sqrt(particleOnexyz[0]**2 - 2*particleOnexyz[0]*particleTwoxyz[0] + particleTwoxyz[0]**2 + particleOnexyz[1]**2 - 2*particleOnexyz[1]*particleTwoxyz[1] + particleTwoxyz[1]**2 + particleOnexyz[2]**2 - \n",
    "         -          2*particleOnexyz[2]*particleTwoxyz[2] + particleTwoxyz[2]**2) + \n",
    "         -       particleOnexyz[0]*particleTwoxyz[0]*(-2*params[0]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -           np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) - \n",
    "         -          4*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -             np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)) + \n",
    "         -          3*params[0]*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2))\n",
    "         -        0 ) + particleTwoxyz[0]**2*(params[0]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -           np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -          2*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -             np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)) - \n",
    "         -          params[0]*(2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2))\n",
    "         -         0 ) + particleOnexyz[0]**2*(params[0]**2*np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -           np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2) + \n",
    "         -          2*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + \n",
    "         -             np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2)) - \n",
    "         -          params[0]*(np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2) + 2*np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2))\n",
    "         -         0 )))/\n",
    "         -  (np.sqrt(particleOnexyz[0]**2 + particleOnexyz[1]**2 + particleOnexyz[2]**2)*\n",
    "         -    (1 + params[1]*np.sqrt((particleOnexyz[0] - particleTwoxyz[0])**2 + (particleOnexyz[1] - particleTwoxyz[1])**2 + (particleOnexyz[2] - particleTwoxyz[2])**2))*\n",
    "         -    np.sqrt((particleOnexyz[0] - particleTwoxyz[0])**2 + (particleOnexyz[1] - particleTwoxyz[1])**2 + (particleOnexyz[2] - particleTwoxyz[2])**2)*\n",
    "         -    np.sqrt(particleTwoxyz[0]**2 + particleTwoxyz[1]**2 + particleTwoxyz[2]**2))\n",
    "    \n",
    "    )\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ab74d8-1e80-44a1-aae3-ac89f02001ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MUST BE FLOAT!!!\n",
    "alpha = 2.0   # initial guess of the parameter\n",
    "beta = 2.0 \n",
    "paramsValuesList = [alpha, beta]       # list of parameters \n",
    "paramsVariableList = [sym.Symbol('a'), sym.Symbol('b')] # list of parameters as symbolic variables \n",
    "\n",
    "\n",
    "\n",
    "patience = 1 # how many times we accept the energy to jump to higher value than the previous energy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a98bba-9122-49ab-a5df-d61305015b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/degnaiyu/Työpöytä/kanditutkielma/kandityo_koodit/main/monteCarloIntegration.py:63: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'params' of function 'probabilityFunction'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3709/120527228.py\", line 1:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  w = probabilityFunction(  trialConfiguration, params  )/probabilityFunction(currentConfig, params)\n",
      "/opt/conda/lib/python3.10/site-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'params' of function 'metropolisSamplingFunction'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"monteCarloIntegration.py\", line 19:\n",
      "@jit(nopython=True)\n",
      "def metropolisSamplingFunction(\n",
      "^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loopMark = 0 # which loop we are going on \n",
    "\n",
    "while patience >= 0: \n",
    "\n",
    "    configSamples_Metropolis = mc.metropolisSamplingFunction(coordinateValueRange = (-1, 1), \n",
    "                                                         numberOfParticles = 2, \n",
    "                                                         numberOfConfig = 10000, \n",
    "                                                         probabilityFunction = probabilityFunction, \n",
    "                                                        numberOfIterations= 100000, \n",
    "                                                          params =  paramsValuesList\n",
    "                                                         ) \n",
    "\n",
    "\n",
    "\n",
    "    # integration approximation using current parameter value \n",
    "    integrationResultAsValue = mc.monteCarloIntegrationFunction(configSamples_Metropolis, localEnergyFunction = localEnergyFunction,  params= paramsValuesList, needError = True)\n",
    "    # save the results to the table \n",
    "    saveToHistoryTable(integrationResultAsValue, paramsValuesList)\n",
    "\n",
    "\n",
    "\n",
    "    # integration approximation with parameter as variable for optimization \n",
    "    # return tuple, where first is the integration result with parameters as variables\n",
    "    integrationResultWithParameter = mc.monteCarloIntegrationFunction(configSamples_Metropolis, localEnergyFunction = localEnergyFunction,  params= paramsVariableList)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # optimization: scipy implementation \n",
    "    def func(y): \n",
    "        y1_float, y2_float  = y \n",
    "        return integrationResultWithParameter[0].subs([(paramsVariableList[0], y1_float),(paramsVariableList[1], y2_float) ])\n",
    "    \n",
    "    \n",
    "    solution = minimize(func, paramsValuesList, method = 'SLSQP')  # minimize using current parameter values \n",
    "    \n",
    "    paramsValuesList = list(solution['x'])  # get the optimized parameters list and update paramsValuesList (global value)\n",
    "\n",
    "    \n",
    "    # transfrom to python float. Avoid issues with sympy.float and numpy.ufunc incompatibility \n",
    "    paramsValuesList = list(map(float, paramsValuesList))   \n",
    "\n",
    "             \n",
    "    \n",
    "    # when we have at least two energy values in the table, we can compare them \n",
    "    if loopMark >= 1: \n",
    "        # if current calculated energy is bigger than energy calculated in the previous loop, reduce patience by 1\n",
    "        if historyTable['Energy'][-1] > historyTable['Energy'][-2]: \n",
    "            patience -= 1\n",
    "    \n",
    "    print(loopMark) \n",
    "    \n",
    "    loopMark += 1 \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b167b2-f222-4fce-8b50-746cb7d71d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "historyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c0436a-ca85-4dbd-a039-cfc2bc793bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sympy.core.add.Add"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(integrationResultWithParameter[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d95e3-8e3f-4821-aad0-eca89b647485",
   "metadata": {},
   "source": [
    "# Testaus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcf3d7-4cf0-4e0c-be2c-f4da768ebd1c",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc2eda16-9c78-40c7-9c3b-f3a2ada1d4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-1.0', '3.98813746927895', '-6.72856476573052']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '-1.0*a**2 + 3.98813746927895*a - 6.72856476573052'\n",
    "re.findall(r'[-]?\\d+[.]{1}\\d+', string.replace(' ', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ee2f8-84ee-45de-bb82-ac4859a0199f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
